"""
è¯¥è„šæœ¬ä½¿ç”¨é€šä¹‰åƒé—® API æ ¹æ®æ–‡æœ¬å†…å®¹ç”Ÿæˆé—®ç­”å¯¹ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º Alpaca æ ¼å¼ä¿å­˜ä¸º JSON æ–‡ä»¶ã€‚
æ£€æµ‹æ–‡ä»¶ç¼–ç å¹¶è¯»å–æ–‡æœ¬å†…å®¹ã€‚
æ ¹æ®æ–‡ä»¶å¤§å°å†³å®šç”Ÿæˆé—®ç­”å¯¹çš„æ•°é‡ã€‚
è°ƒç”¨é€šä¹‰åƒé—® API ç”Ÿæˆé—®ç­”å¯¹ã€‚
å°†é—®ç­”å¯¹è½¬æ¢ä¸º Alpaca æ ¼å¼å¹¶ä¿å­˜ä¸º JSON æ–‡ä»¶ã€‚
"""
import os
import json
import chardet
from pathlib import Path
import dashscope#å¯¼å…¥é€šä¹‰åƒé—®SDKï¼Œç”¨äºè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆé—®ç­”

# è®¾ç½®ä½ çš„é€šä¹‰åƒé—® API å¯†é’¥ï¼Œç”¨äºè®¤è¯ä½ è°ƒç”¨é€šä¹‰åƒé—®APIçš„èº«ä»½
dashscope.api_key = 'sk-'  # â†â†â† æ›¿æ¢ä¸ºä½ çš„å¯†é’¥

# è‡ªå®šä¹‰è¾“å‡ºæ–‡ä»¶å¤¹ï¼Œåˆ›å»ºä¸€ä¸ª Path å¯¹è±¡ï¼Œè¡¨ç¤ºè¾“å‡º JSON æ–‡ä»¶å­˜æ”¾çš„ç›®å½•ã€‚
OUTPUT_DIR = Path(r"F:\PhD-item-experment\answer\knowledge\knowledgecode\Code\dataset_processing\text_to_qa")  # â†â†â† ä½ å¯ä»¥ä¿®æ”¹ä¸ºä»»æ„è·¯å¾„
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)#å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºã€‚å¦‚æœå­˜åœ¨ï¼Œä¸æŠ¥é”™

"""æ£€æµ‹æ–‡æœ¬æ–‡ä»¶çš„ç¼–ç """
def detect_encoding(file_path):
    with open(file_path, 'rb') as f:#ä»¥äºŒè¿›åˆ¶æ‰“å¼€æ–‡ä»¶ï¼Œå› ä¸ºchardetéœ€è¦åŸå§‹å­—èŠ‚
        raw_data = f.read()#è¯»å‡ºå…¨éƒ¨å­—èŠ‚å†…å®¹
    result = chardet.detect(raw_data)#ç”¨ chardet æ£€æµ‹ç¼–ç ï¼Œè¿”å›ä¸€ä¸ªå­—å…¸
    return result['encoding'] or 'utf-8'#å–æ£€æµ‹åˆ°çš„ç¼–ç ï¼Œå¦‚æœæ²¡æœ‰æ£€æµ‹å‡ºæ¥é»˜è®¤utf-8

def read_text(file_path):
    encoding = detect_encoding(file_path)#å…ˆæ£€æµ‹æ–‡ä»¶ç¼–ç æ–¹å¼
    with open(file_path, 'r', encoding=encoding, errors='ignore') as f:#æŒ‰æ–‡ä»¶ç¼–ç æ–¹å¼ä»¥æ–‡æœ¬æ¨¡å¼ræ‰“å¼€æ–‡ä»¶ï¼ŒæŠŠæ•´ä¸ªæ–‡ä»¶å†…å®¹è¯»æˆä¸€ä¸ªå­—ç¬¦ä¸²è¿”å›
        return f.read()

"""æ ¹æ®æ–‡ä»¶å¤§å°å†³å®šé—®ç­”å¯¹æ•°é‡"""
def decide_qa_count(file_size_bytes):
    kb = file_size_bytes / 1024
    if kb < 5:
        return 5
    elif kb < 20:
        return 10
    elif kb < 50:
        return 15
    elif kb < 100:
        return 20
    elif kb < 300:
        return 30
    elif kb < 600:
        return 40
    else:
        return 50
"""è°ƒç”¨é€šä¹‰åƒé—®ç”Ÿæˆé—®ç­”å¯¹
textï¼šæ•´ä¸ªæ–‡ç« å†…å®¹
qa_countï¼šå¸Œæœ›ç”Ÿæˆçš„é—®ç­”å¯¹æ•°é‡
"""
def generate_qa_pairs(text, qa_count):
    prompt = (
        f"è¯·æ ¹æ®ä»¥ä¸‹æ–‡æœ¬å†…å®¹ç”Ÿæˆä¸å°‘äº{qa_count}ä¸ªçŸ¥è¯†æ€§é—®ç­”å¯¹ï¼Œå†…å®¹åº”åŒ…æ‹¬å®šä¹‰ã€åŸç†ã€åº”ç”¨ã€ä¼˜åŠ¿ã€æ³¨æ„äº‹é¡¹ç­‰ï¼Œ"
        "å¹¶è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ å½¢å¦‚ï¼š{\"question\": \"...\", \"answer\": \"...\"}ã€‚\n\n"
        f"{text}\n\n"
        "è¯·ç¡®ä¿æ ¼å¼æ­£ç¡®ã€å†…å®¹å‡†ç¡®ï¼Œå¹¶ä»…è¿”å› JSON æ•°ç»„ã€‚"
    )#æ„é€ è¦å‘ç»™å¤§æ¨¡å‹çš„æç¤ºè¯ï¼Œ
    #ç”¨ä¸­æ–‡è¯´æ˜ä»»åŠ¡ï¼šæ ¹æ®æ–‡æœ¬ç”Ÿæˆä¸å°‘äº qa_count ä¸ªçŸ¥è¯†æ€§é—®ç­”å¯¹ã€‚
    # è¦æ±‚è¿”å› JSON æ•°ç»„ï¼Œå…ƒç´ æ ¼å¼ä¸º {"question": "...", "answer": "..."}ã€‚
    #æŠŠåŸå§‹æ–‡æœ¬ text æ‹¼æ¥åˆ°æç¤ºè¯åé¢ã€‚
    #æœ€åå¼ºè°ƒï¼šåªè¿”å› JSON æ•°ç»„ã€‚

    try:
        response = dashscope.Generation.call(
            model='qwen-turbo',
            messages=[
                {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªé—®ç­”ç”ŸæˆåŠ©æ‰‹ã€‚'},#è®¾å®šæ¨¡å‹è§’è‰²
                {'role': 'user', 'content': prompt}#ç”¨æˆ·çš„å†…å®¹å°±æ˜¯ä¸Šé¢æ„é€ çš„prompt
            ],
            result_format='message',#æŒ‡å®šè¿”å›æ ¼å¼ä¸ºâ€œmessageâ€å½¢å¼ï¼ˆSDK è‡ªå·±çš„æ ¼å¼ï¼‰
            temperature=0.7,#é»˜è®¤å€¼
            max_tokens=2048  # é™åˆ¶æ¨¡å‹æœ€å¤§è¾“å‡ºé•¿åº¦
        )#è°ƒç”¨é€šä¹‰åƒé—®ç”Ÿæˆæ¥å£
        print(response)
        content = response['output']['choices'][0]['message']['content'].strip()#æå–é€šä¹‰åƒé—®æ¨¡å‹å®é™…ç”Ÿæˆçš„å†…å®¹ï¼Œå¹¶å»æ‰é¦–å°¾ç©ºç™½å­—ç¬¦
        json_start = content.find('[')#æ‰¾åˆ°ç¬¬ä¸€ä¸ª[çš„ä½ç½®
        json_end = content.rfind(']') + 1#æ‰¾åˆ°æœ€åä¸€ä¸ª ] çš„ä½ç½®å†åŠ  1

        #å–å‡ºä»ç¬¬ä¸€ä¸ª[åˆ°æœ€åä¸€ä¸ª]çš„å­—ä¸²ï¼ŒæŠŠè¿™ä¸ªå­—ç¬¦é™¤æŒ‰è§£ææˆpythonåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å°±æ˜¯ä¸€ä¸ªå­—å…¸
        qa_list = json.loads(content[json_start:json_end])
        return qa_list#è¿”å›é—®ç­”å¯¹åˆ—è¡¨
    except Exception as e:
        print(f"[âŒ ERROR] API è°ƒç”¨å¤±è´¥æˆ– JSON è§£æé”™è¯¯ï¼š{e}")
        return []
"""å¤„ç†ä¸€ä¸ªæ–‡ä»¶å¤¹é‡Œçš„æ‰€æœ‰txtæ–‡ä»¶"""
def process_folder(input_folder):
    folder = Path(input_folder)
    txt_files = list(folder.glob("*.txt"))#æ‰€æœ‰txtæ–‡ä»¶è·¯å¾„
    if not txt_files:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ° .txt æ–‡ä»¶")
        return

    for txt_path in txt_files:
        print(f"\nğŸ“„ æ­£åœ¨å¤„ç†: {txt_path.name}")
        file_size = txt_path.stat().st_size#è¿”å›æ–‡ä»¶å¤§å° 30585517B
        #30585517 å­—èŠ‚ â‰ˆ 29868.7 KBï¼Œç”Ÿæˆ 50 ä¸ªé—®ç­”å¯¹
        qa_count = decide_qa_count(file_size)#ç”Ÿæˆçš„é—®ç­”å¯¹ä¸ªæ•°
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ â‰ˆ {file_size/1024:.1f} KBï¼Œç”Ÿæˆ {qa_count} ä¸ªé—®ç­”å¯¹")

        text = read_text(txt_path)#è¯»å–æ–‡æœ¬å†…å®¹
        if not text.strip():
            print("âš ï¸ æ–‡æœ¬å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
            continue

        qa_pairs = generate_qa_pairs(text, qa_count)#ä¼ å…¥å…¨æ–‡å†…å®¹å’Œé—®ç­”æ•°é‡ï¼Œè°ƒç”¨é€šä¹‰åƒé—®ã€‚ç”Ÿæˆé—®ç­”å¯¹
        if not qa_pairs:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆé—®ç­”å¯¹")
            continue

        # è½¬æ¢ä¸º Alpaca æ ¼å¼
        alpaca_data = []
        output_path = OUTPUT_DIR / f"{txt_path.stem}.json"#abc.txt â†’ abc
        if output_path.exists():
            print(f"â© å·²å­˜åœ¨è½¬æ¢æ–‡ä»¶ï¼Œè·³è¿‡ï¼š{output_path.name}")
            continue
        for pair in qa_pairs:#éå†æ¯ä¸€ä¸ªé—®ç­”å¯¹
            if isinstance(pair, str):
                try:
                    pair = json.loads(pair)
                    print(pair)
                except json.JSONDecodeError:
                    print(f"âš ï¸ è·³è¿‡æ— æ³•è§£æçš„é—®ç­”å¯¹ï¼š{pair}")
                    continue
            if not isinstance(pair, dict):
                print(f"âš ï¸ è·³è¿‡éå­—å…¸æ ¼å¼çš„é—®ç­”å¯¹ï¼š{pair}")
                continue
            question = pair.get("question", "").strip()#å–å‡ºquestionå­—æ®µå¹¶å»æ‰é¦–å°¾ç©ºç™½
            answer = pair.get("answer", "").strip()
            if question and answer:#éƒ½éç©º
                alpaca_data.append({
                    "instruction": question,#é—®é¢˜
                    "input": "",#æœ‰äº›ä»»åŠ¡ä¼šç”¨inputä¼ å…¥ä¸Šä¸‹æ–‡
                    "output": answer#ç­”æ¡ˆ
                })

        # å†™å…¥ JSON æ–‡ä»¶ï¼ˆä»…åŒ…å«é—®ç­”å¯¹åˆ—è¡¨ï¼‰
        with open(output_path, "w", encoding="utf-8") as f:#ä»¥å†™æ¨¡å¼ã€utf-8 ç¼–ç æ‰“å¼€è¾“å‡ºæ–‡ä»¶
            json.dump(alpaca_data, f, ensure_ascii=False, indent=2)#æŠŠalpaca_dataå†™å…¥jsonæ–‡ä»¶ï¼Œä¿è¯ç›´æ¥å†™å…¥ä¸­æ–‡ï¼Œç¼©è¿›2ä¸ªç©ºæ ¼æ–¹ä¾¿é˜…è¯»

        print(f"âœ… å·²ä¿å­˜ï¼ˆAlpaca æ ¼å¼ï¼‰ï¼š{output_path.resolve()}")

if __name__ == "__main__":
    #ä¿®æ”¹è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
    input_dir = r"F:\PhD-item-experment\answer\knowledge\knowledgecode\Code\dataset_processing\wordtxt"  # â†â†â† æ›¿æ¢ä¸ºä½ çš„è¾“å…¥è·¯å¾„
    process_folder(input_dir)
